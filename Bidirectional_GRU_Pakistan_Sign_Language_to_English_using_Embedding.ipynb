{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bidirectional GRU Pakistan Sign Language to English using Embedding.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARsLIT-_DXwd",
        "outputId": "4e562557-d45b-4292-d7b6-0039064f0ccd"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dnMWFOOEFlP"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import string\n",
        "import re\n",
        "from unicodedata import normalize\n",
        "import numpy as np\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential,load_model\n",
        "from keras.layers import LSTM,Dense,Embedding,RepeatVector,TimeDistributed,Bidirectional,GRU\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "import pandas as pd\n",
        "from string import punctuation\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Markdown, display\n",
        "from keras.layers import Dropout\n",
        "\n",
        "\n",
        "def printmd(string):\n",
        "    # Print with Markdowns    \n",
        "    display(Markdown(string))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "id": "F3_CmcLzEFoG",
        "outputId": "83c9c580-436d-44c4-bfae-ddd7cde16fb8"
      },
      "source": [
        "# How many sentences will be used\n",
        "# Limit the sentences to 10.000 on Kaggle to avoid exceding the\n",
        "# available RAM space\n",
        "# Build a generator to avoid this issue\n",
        "\n",
        "total_sentences = 85221\n",
        "\n",
        "# Load the dataset\n",
        "dataset = pd.read_excel(\"/content/drive/MyDrive/FYP/data.xlsx\", nrows = total_sentences)\n",
        "\n",
        "\n",
        "# What proportion of the sentences will be used for the test set\n",
        "test_proportion = 0.3\n",
        "train_test_threshold = int( (1-test_proportion) * total_sentences)\n",
        "\n",
        "printmd(f'## {total_sentences} \"parallel sentences\" will be loaded (original sentence + its translation)')\n",
        "printmd(f'## {train_test_threshold} \"parallel sentences\" will be used to train the model')\n",
        "printmd(f'## {total_sentences-train_test_threshold} \"parallel sentences\" will be used to test the model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "## 85221 \"parallel sentences\" will be loaded (original sentence + its translation)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "## 59654 \"parallel sentences\" will be used to train the model",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "## 25567 \"parallel sentences\" will be used to test the model",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "_pJwPsIlEFqS",
        "outputId": "e80c6ce4-f693-463a-fcef-94bdc62938dd"
      },
      "source": [
        "# Shuffle the dataset\n",
        "dataset = dataset.sample(frac=1, random_state=0)\n",
        "dataset.iloc[1000:1010]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>PSL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>42870</th>\n",
              "      <td>The chief was deciding to be a good man.</td>\n",
              "      <td>Was The chief be a good man decides to now.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3261</th>\n",
              "      <td>I have an orange and an apple.</td>\n",
              "      <td>I an orange an apple have.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73922</th>\n",
              "      <td>I had hoped to meet her there.</td>\n",
              "      <td>was I there her meet hope full.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84184</th>\n",
              "      <td>I know that Shazim is agnostic.</td>\n",
              "      <td>I know that Shazim agnostic.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79760</th>\n",
              "      <td>He is a director and should be treated as such.</td>\n",
              "      <td>He director such treat.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61886</th>\n",
              "      <td>I can not believe Anees said yes.</td>\n",
              "      <td>I believe not was Anees say.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65728</th>\n",
              "      <td>Waasif did not follow the rules.</td>\n",
              "      <td>was Waasif rules follow not.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36340</th>\n",
              "      <td>It sounds very strange to me.</td>\n",
              "      <td>It me very strange sounds.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4064</th>\n",
              "      <td>Balam took off his belt.</td>\n",
              "      <td>was Balam his belt take off.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24879</th>\n",
              "      <td>We have just got to keep going.</td>\n",
              "      <td>We just go keep get full.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               English                                          PSL\n",
              "42870         The chief was deciding to be a good man.  Was The chief be a good man decides to now.\n",
              "3261                    I have an orange and an apple.                   I an orange an apple have.\n",
              "73922                   I had hoped to meet her there.              was I there her meet hope full.\n",
              "84184                  I know that Shazim is agnostic.                 I know that Shazim agnostic.\n",
              "79760  He is a director and should be treated as such.                      He director such treat.\n",
              "61886                I can not believe Anees said yes.                 I believe not was Anees say.\n",
              "65728                 Waasif did not follow the rules.                 was Waasif rules follow not.\n",
              "36340                    It sounds very strange to me.                   It me very strange sounds.\n",
              "4064                          Balam took off his belt.                 was Balam his belt take off.\n",
              "24879                  We have just got to keep going.                    We just go keep get full."
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYdNUb4WEFsx"
      },
      "source": [
        "def clean(string):\n",
        "    # Clean the string\n",
        "    string = string.replace(\"\\u202f\",\" \") # Replace no-break space with space\n",
        "    string = string.lower()\n",
        "    \n",
        "    # Delete the punctuation and the numbers\n",
        "    for p in punctuation + \"«»\" + \"0123456789\":\n",
        "        string = string.replace(p,\" \")\n",
        "        \n",
        "        \n",
        "    string = re.sub('\\s+',' ', string)\n",
        "    string = string.strip()\n",
        "           \n",
        "    return string\n",
        "\n",
        "# Clean the sentences\n",
        "dataset[\"English\"] = dataset[\"English\"].apply(lambda x: clean(x))\n",
        "dataset[\"PSL\"] = dataset[\"PSL\"].apply(lambda x: clean(x))\n",
        "\n",
        "# Select one part of the dataset\n",
        "dataset = dataset.values\n",
        "dataset = dataset[:total_sentences]\n",
        "\n",
        "# split into train/test\n",
        "train, test = dataset[:train_test_threshold], dataset[train_test_threshold:]\n",
        "\n",
        "# Define the name of the source and of the target\n",
        "# This will be used in the outputs of this notebook\n",
        "source_str, target_str = \"PSL\", \"English\"\n",
        "\n",
        "# The index in the numpy array of the source and of the target\n",
        "idx_src, idx_tar = 1,0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "id": "Ti9qBNdCERi_",
        "outputId": "b29f3e71-f168-4778-83ad-833eec27f771"
      },
      "source": [
        "def create_tokenizer(lines):\n",
        "    # fit a tokenizer\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(lines)\n",
        "    return tokenizer\n",
        " \n",
        "def max_len(lines):\n",
        "    # max sentence length\n",
        "    return max(len(line.split()) for line in lines)\n",
        "\n",
        "def encode_sequences(tokenizer, length, lines):\n",
        "    # encode and pad sequences\n",
        "    X = tokenizer.texts_to_sequences(lines) # integer encode sequences\n",
        "    X = pad_sequences(X, maxlen=length, padding='post') # pad sequences with 0 values\n",
        "    return X\n",
        " \n",
        "def encode_output(sequences, vocab_size):\n",
        "    # one hot encode target sequence\n",
        "    ylist = list()\n",
        "    for sequence in sequences:\n",
        "        encoded = to_categorical(sequence, num_classes=vocab_size)\n",
        "        ylist.append(encoded)\n",
        "    y = np.array(ylist)\n",
        "    y = y.reshape(sequences.shape[0], sequences.shape[1], vocab_size)\n",
        "    return y\n",
        " \n",
        "# Prepare target tokenizer\n",
        "tar_tokenizer = create_tokenizer(dataset[:, idx_tar])\n",
        "tar_vocab_size = len(tar_tokenizer.word_index) + 1\n",
        "tar_length = max_len(dataset[:, idx_tar])\n",
        "printmd(f'\\nTarget ({target_str}) Vocabulary Size: {tar_vocab_size}')\n",
        "printmd(f'Target ({target_str}) Max Length: {tar_length}')\n",
        "\n",
        "# Prepare source tokenizer\n",
        "src_tokenizer = create_tokenizer(dataset[:, idx_src])\n",
        "src_vocab_size = len(src_tokenizer.word_index) + 1\n",
        "src_length = max_len(dataset[:, idx_src])\n",
        "printmd(f'\\nSource ({source_str}) Vocabulary Size: {src_vocab_size}')\n",
        "printmd(f'Source ({source_str}) Max Length: {src_length}\\n')\n",
        " \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "\nTarget (English) Vocabulary Size: 9256",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "Target (English) Max Length: 12",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "\nSource (PSL) Vocabulary Size: 8089",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "Source (PSL) Max Length: 14\n",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-LAxZVoEUQl"
      },
      "source": [
        "# Glove"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9QqIakWERl2",
        "outputId": "f166a7a1-7f43-4494-e62a-e80c9222414b"
      },
      "source": [
        "# load embeding for text file\n",
        "embeddings_index = dict()\n",
        "f = open('/content/drive/MyDrive/glove.6B.300d.txt')\n",
        "\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('Loaded %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRfVS6_tERoW"
      },
      "source": [
        "dims=300\n",
        "flag=1\n",
        "word_index = {w: i for i, w in enumerate(embeddings_index, 1)}\n",
        "embedding_matrix = np.zeros((len(word_index)+1, dims))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector[:dims]\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXKMifdQERqb"
      },
      "source": [
        "# Prepare training data\n",
        "trainX = encode_sequences(src_tokenizer, src_length, train[8000:16000, idx_src])\n",
        "trainY = encode_sequences(tar_tokenizer, tar_length, train[8000:16000, idx_tar])\n",
        "trainY = encode_output(trainY, tar_vocab_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LI7MSrXfERst"
      },
      "source": [
        "def create_model(src_vocab, tar_vocab, src_timesteps, tar_timesteps, n_units):\n",
        "    # Create the model\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(embedding_matrix.shape[0],embedding_matrix.shape[1],weights=[embedding_matrix],input_length=src_timesteps,trainable=False))\n",
        "    model.add(Bidirectional(GRU(n_units)))\n",
        "    model.add(RepeatVector(tar_timesteps))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Bidirectional(GRU(n_units, return_sequences=True)))\n",
        "\n",
        "    model.add(TimeDistributed(Dense(tar_vocab, activation='sigmoid')))\n",
        "    return model\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBnZx5QEERvC"
      },
      "source": [
        "# Create model\n",
        "model = create_model(src_vocab_size, tar_vocab_size, src_length, tar_length, 256)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SdXM6_HERxF",
        "outputId": "56ff13e2-9d33-40a0-d4cf-9e50775d0b36"
      },
      "source": [
        "history = model.fit(trainX, \n",
        "          trainY, \n",
        "          epochs=100, \n",
        "          batch_size=128, \n",
        "          validation_split=0.2, \n",
        "          verbose=1,\n",
        "          callbacks=[\n",
        "                        EarlyStopping(\n",
        "                        monitor='val_loss',\n",
        "                        patience=10,\n",
        "                        restore_best_weights=True\n",
        "                    )\n",
        "            ])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "50/50 [==============================] - 14s 145ms/step - loss: 1.6793 - val_loss: 1.5742\n",
            "Epoch 2/100\n",
            "50/50 [==============================] - 5s 98ms/step - loss: 1.3189 - val_loss: 1.4893\n",
            "Epoch 3/100\n",
            "50/50 [==============================] - 5s 102ms/step - loss: 1.0901 - val_loss: 1.4483\n",
            "Epoch 4/100\n",
            "50/50 [==============================] - 5s 105ms/step - loss: 0.9318 - val_loss: 1.4185\n",
            "Epoch 5/100\n",
            "50/50 [==============================] - 5s 101ms/step - loss: 0.8007 - val_loss: 1.3941\n",
            "Epoch 6/100\n",
            "50/50 [==============================] - 5s 103ms/step - loss: 0.7005 - val_loss: 1.4027\n",
            "Epoch 7/100\n",
            "50/50 [==============================] - 5s 103ms/step - loss: 0.6272 - val_loss: 1.3868\n",
            "Epoch 8/100\n",
            "50/50 [==============================] - 5s 104ms/step - loss: 0.5605 - val_loss: 1.3939\n",
            "Epoch 9/100\n",
            "50/50 [==============================] - 5s 103ms/step - loss: 0.5057 - val_loss: 1.3757\n",
            "Epoch 10/100\n",
            "50/50 [==============================] - 5s 101ms/step - loss: 0.4598 - val_loss: 1.3775\n",
            "Epoch 11/100\n",
            "50/50 [==============================] - 5s 102ms/step - loss: 0.4199 - val_loss: 1.3843\n",
            "Epoch 12/100\n",
            "50/50 [==============================] - 5s 105ms/step - loss: 0.3907 - val_loss: 1.3831\n",
            "Epoch 13/100\n",
            "50/50 [==============================] - 5s 102ms/step - loss: 0.3634 - val_loss: 1.3796\n",
            "Epoch 14/100\n",
            "50/50 [==============================] - 5s 104ms/step - loss: 0.3352 - val_loss: 1.3849\n",
            "Epoch 15/100\n",
            "50/50 [==============================] - 5s 106ms/step - loss: 0.3154 - val_loss: 1.3864\n",
            "Epoch 16/100\n",
            "50/50 [==============================] - 5s 102ms/step - loss: 0.2964 - val_loss: 1.3858\n",
            "Epoch 17/100\n",
            "50/50 [==============================] - 5s 102ms/step - loss: 0.2786 - val_loss: 1.3858\n",
            "Epoch 18/100\n",
            "50/50 [==============================] - 5s 104ms/step - loss: 0.2626 - val_loss: 1.3920\n",
            "Epoch 19/100\n",
            "50/50 [==============================] - 5s 103ms/step - loss: 0.2493 - val_loss: 1.4038\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAni5JIeERzS"
      },
      "source": [
        "model.save('/content/drive/MyDrive/FYP/GRU Golvee Model/bigrumodel.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BMmjPVrEFu-"
      },
      "source": [
        "from tensorflow import keras\n",
        "model = keras.models.load_model('/content/drive/MyDrive/FYP/GRU Golvee Model/bigrumodel.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EukxL5T3EFxN",
        "outputId": "bb92bd11-8dfd-4aa5-ac6d-759909a743f4"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 14, 300)           120000300 \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 512)               857088    \n",
            "_________________________________________________________________\n",
            "repeat_vector (RepeatVector) (None, 12, 512)           0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 12, 512)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 12, 512)           1182720   \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 12, 9256)          4748328   \n",
            "=================================================================\n",
            "Total params: 126,788,436\n",
            "Trainable params: 6,788,136\n",
            "Non-trainable params: 120,000,300\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeUBMySPQjTp"
      },
      "source": [
        "# Testing Phase with Golvee"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jq7Mc4iQrgt"
      },
      "source": [
        "# Prepare test data\n",
        "testX = encode_sequences(src_tokenizer, src_length, test[20000:25567, idx_src])\n",
        "testY = encode_sequences(tar_tokenizer, tar_length, test[20000:25567, idx_tar])\n",
        "testY = encode_output(testY, tar_vocab_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkrK8eDOQybK",
        "outputId": "6e9c0d04-711f-4b2b-9ace-da684243cd4d"
      },
      "source": [
        "def word_for_id(integer, tokenizer):\n",
        "    # map an integer to a word\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == integer:\n",
        "            return word\n",
        "    return None\n",
        " \n",
        "def predict_seq(model, tokenizer, source):\n",
        "    # generate target from a source sequence\n",
        "    prediction = model.predict(source, verbose=0)[0]\n",
        "    integers = [np.argmax(vector) for vector in prediction]\n",
        "    target = list()\n",
        "    \n",
        "    for i in integers:\n",
        "        word = word_for_id(i, tokenizer)\n",
        "        if word is None:\n",
        "            break\n",
        "        target.append(word)\n",
        "    return ' '.join(target)\n",
        "\n",
        "def compare_prediction(model, tokenizer, sources, raw_dataset, limit=20):\n",
        "    # evaluate a model\n",
        "    actual, predicted = [], []\n",
        "    src = f'{source_str.upper()} (SOURCE)'\n",
        "    tgt = f'{target_str.upper()} (TARGET)'\n",
        "    pred = f'AUTOMATIC TRANSLATION IN {target_str.upper()}'\n",
        "    print(f'{src:30} {tgt:25} {pred}\\n')\n",
        "    \n",
        "    for i, source in enumerate(sources): # translate encoded source text\n",
        "        source = source.reshape((1, source.shape[0]))\n",
        "        translation = predict_seq(model, tar_tokenizer, source)\n",
        "        raw_target, raw_src = raw_dataset[i]\n",
        "        print(f'{raw_src:30} {raw_target:25} {translation}')\n",
        "        if i >= limit: # Display some of the result\n",
        "            break\n",
        " \n",
        "# test on some training sequences\n",
        "# print('### Result on the Training Set ###')\n",
        "# compare_prediction(model, tar_tokenizer, trainX, train)\n",
        "\n",
        "# test on some test sequences\n",
        "print('\\n\\n### Result on the Test Set ###')\n",
        "compare_prediction(model, tar_tokenizer, testX,test[:10000,:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "### Result on the Test Set ###\n",
            "PSL (SOURCE)                   ENGLISH (TARGET)          AUTOMATIC TRANSLATION IN ENGLISH\n",
            "\n",
            "was she food cook full         she had cooked food       she had cooked food\n",
            "was i them tell not            i did not tell them       i did not tell them\n",
            "i stupid feel                  i feel stupid             i feel stupid\n",
            "ranjhoo it like after          ranjhoo will like it      ranjhoo will like it\n",
            "was they their parents obey not they did not obey their parents they did not carry their bag\n",
            "hello                          hello                     hello\n",
            "i brothers sisters have        i have eight brothers and sisters i have brothers brothers\n",
            "i now go go now                i am going to go now      i am going to go now\n",
            "i join in yes no               can i join in             can i join in\n",
            "was it important               it was important          it was important\n",
            "you mail full                  you have mail             you have girl\n",
            "everybody know i you hate      everybody knows i hate you everybody knows i hate you\n",
            "was i you totally              i was totally into you    i was totally you\n",
            "was you part get               you got the part          you got part\n",
            "was i it properly handle       i handled it properly     i was it it\n",
            "was javaid say that was bakhtawar lucky not javaid said that bakhtawar was not lucky javaid said that bakhtawar was not lucky\n",
            "was waasif lamp turn off       waasif turned off the lamp the turned off the the off\n",
            "we them trust yes no           can we trust them         can we trust them\n",
            "was my mother them sew full now not my mother had not been sewing them my mother had not been sewing them\n",
            "was kitten milk drink full now the kitten had been drinking milk the kitten had been drinking milk\n",
            "was husnain champagne drink want husnain wanted to drink champagne husnain wanted to be a\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hesw3kDnQymF"
      },
      "source": [
        "## Bleu Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "au4mwwGUQyp9"
      },
      "source": [
        "def bleu_score(model, tokenizer, sources, raw_dataset):\n",
        "    # Get the bleu score of a model\n",
        "    actual, predicted = [], []\n",
        "    for i, source in enumerate(sources):\n",
        "        # translate encoded source text\n",
        "        source = source.reshape((1, source.shape[0]))\n",
        "        translation = predict_seq(model, tar_tokenizer, source)\n",
        "        raw_target, raw_src = raw_dataset[i]\n",
        "        actual.append([raw_target.split()])\n",
        "        predicted.append(translation.split())\n",
        "        \n",
        "    bleu_dic = {}\n",
        "    bleu_dic['1-grams'] = corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0))\n",
        "    bleu_dic['1-2-grams'] = corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0))\n",
        "    bleu_dic['1-3-grams'] = corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0))\n",
        "    bleu_dic['1-4-grams'] = corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25))\n",
        "    \n",
        "    return bleu_dic\n",
        "\n",
        "# Compute the BLEU Score\n",
        "# bleu_train = bleu_score(model, tar_tokenizer, trainX, train)\n",
        "bleu_test = bleu_score(model, tar_tokenizer, testX, test[:10000,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "BMcwoHWyQyrc",
        "outputId": "ac79508e-41ac-4b2b-befa-8c09004cab49"
      },
      "source": [
        "plt.bar(x = bleu_test.keys(), height = bleu_test.values())\n",
        "plt.title(\"BLEU Score with the first 10000 test set\")\n",
        "plt.ylim((0,1))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84iFl0vkQytI",
        "outputId": "4585d4d6-b3fb-4812-dfbe-6c35fbe32759"
      },
      "source": [
        "print(bleu_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'1-grams': 0.7232302157936887, '1-2-grams': 0.6150046669667623, '1-3-grams': 0.5613931268421277, '1-4-grams': 0.4530424787595973}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itnWL3jKQyvq"
      },
      "source": [
        "## WER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29C-NSVwQyyE",
        "outputId": "c9765efb-27d3-4a7b-88b3-38b03b3dcb3f"
      },
      "source": [
        "def word_for_id(integer, tokenizer):\n",
        "    # map an integer to a word\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == integer:\n",
        "            return word\n",
        "    return None\n",
        " \n",
        "def predict_seq(model, tokenizer, source):\n",
        "    # generate target from a source sequence\n",
        "    prediction = model.predict(source, verbose=0)[0]\n",
        "    integers = [np.argmax(vector) for vector in prediction]\n",
        "    target = list()\n",
        "    \n",
        "    for i in integers:\n",
        "        word = word_for_id(i, tokenizer)\n",
        "        if word is None:\n",
        "            break\n",
        "        target.append(word)\n",
        "    return ' '.join(target)\n",
        "\n",
        "def compare_prediction(model, tokenizer, sources, raw_dataset, limit=20):\n",
        "    # evaluate a model\n",
        "    actual, predicted = [], []\n",
        "    src = f'{source_str.upper()} (SOURCE)'\n",
        "    tgt = f'{target_str.upper()} (TARGET)'\n",
        "    pred = f'AUTOMATIC TRANSLATION IN {target_str.upper()}'\n",
        "    #print(f'{src:30} {tgt:25} {pred}\\n')\n",
        "    \n",
        "    for i, source in enumerate(sources): # translate encoded source text\n",
        "        source = source.reshape((1, source.shape[0]))\n",
        "        translation = predict_seq(model, tar_tokenizer, source)\n",
        "        raw_target, raw_src = raw_dataset[i]\n",
        "        #print(f'{raw_src:30} {raw_target:25} {translation}')\n",
        "        #print(translation)     #predicit\n",
        "        #print(raw_target)      #actual\n",
        "        actual.append(raw_target)\n",
        "        predicted.append(translation)\n",
        "        if i >= limit: # Display some of the result\n",
        "            return actual,predicted\n",
        "            break\n",
        " \n",
        "# # test on some training sequences!pip install jiwer\n",
        "# print('### Result on the Training Set ###')\n",
        "# compare_prediction(model, tar_tokenizer, trainX, train)\n",
        "\n",
        "# test on some test sequences\n",
        "print('\\n\\n### Result on the Test Set ###')\n",
        "Actual,Predicted=compare_prediction(model, tar_tokenizer, testX,test[:10000,:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "### Result on the Test Set ###\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zu3RnarMQy0o",
        "outputId": "611065a6-a58a-431b-df61-809e54e45190"
      },
      "source": [
        "!pip install jiwer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting jiwer\n",
            "  Downloading jiwer-2.2.0-py3-none-any.whl (13 kB)\n",
            "Collecting python-Levenshtein\n",
            "  Downloading python-Levenshtein-0.12.2.tar.gz (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 3.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from jiwer) (1.19.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from python-Levenshtein->jiwer) (57.4.0)\n",
            "Building wheels for collected packages: python-Levenshtein\n",
            "  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.2-cp37-cp37m-linux_x86_64.whl size=149862 sha256=65fb5406b855f3b478f2f35e54d807bd722bb0d71f97977f08cfa058cdd00e3d\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/5f/ca/7c4367734892581bb5ff896f15027a932c551080b2abd3e00d\n",
            "Successfully built python-Levenshtein\n",
            "Installing collected packages: python-Levenshtein, jiwer\n",
            "Successfully installed jiwer-2.2.0 python-Levenshtein-0.12.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgsqxfukQy33",
        "outputId": "e921c563-ee9c-48c8-d2cc-5ccfa5288917"
      },
      "source": [
        "from jiwer import wer\n",
        "error=wer(Actual,Predicted)\n",
        "error"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.15463917525773196"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3DZq6heRHbR"
      },
      "source": [
        "## TER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djdUPVYBQy6F",
        "outputId": "cb31f6e9-d1ba-4bbe-bcbf-db52f11d2360"
      },
      "source": [
        "!pip install pyter3\n",
        "import pyter"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyter3\n",
            "  Downloading pyter3-0.3-py3-none-any.whl (4.1 kB)\n",
            "Installing collected packages: pyter3\n",
            "Successfully installed pyter3-0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQAk2AnGQy91",
        "outputId": "1381c387-e4e6-4ca0-f298-a78eba127d7d"
      },
      "source": [
        "i=0\n",
        "sum=0\n",
        "while i<len(Actual):\n",
        "  #print(pyter.ter(Actual[i].split(),Predicted[i].split()))\n",
        "  sum+=pyter.ter(Actual[i].split(),Predicted[i].split())\n",
        "  i=i+1\n",
        "\n",
        "\n",
        "\n",
        "sum=sum/len(Actual)\n",
        "sum"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1619047619047619"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzPzL8z4R_Az"
      },
      "source": [
        "# For 2nd 10000 testing Instance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uX3g6hhSBEO",
        "outputId": "fc9ef901-0adc-4c4d-ce53-c7459f3402f4"
      },
      "source": [
        "def word_for_id(integer, tokenizer):\n",
        "    # map an integer to a word\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == integer:\n",
        "            return word\n",
        "    return None\n",
        " \n",
        "def predict_seq(model, tokenizer, source):\n",
        "    # generate target from a source sequence\n",
        "    prediction = model.predict(source, verbose=0)[0]\n",
        "    integers = [np.argmax(vector) for vector in prediction]\n",
        "    target = list()\n",
        "    \n",
        "    for i in integers:\n",
        "        word = word_for_id(i, tokenizer)\n",
        "        if word is None:\n",
        "            break\n",
        "        target.append(word)\n",
        "    return ' '.join(target)\n",
        "\n",
        "def compare_prediction(model, tokenizer, sources, raw_dataset, limit=20):\n",
        "    # evaluate a model\n",
        "    actual, predicted = [], []\n",
        "    src = f'{source_str.upper()} (SOURCE)'\n",
        "    tgt = f'{target_str.upper()} (TARGET)'\n",
        "    pred = f'AUTOMATIC TRANSLATION IN {target_str.upper()}'\n",
        "    print(f'{src:30} {tgt:25} {pred}\\n')\n",
        "    \n",
        "    for i, source in enumerate(sources): # translate encoded source text\n",
        "        source = source.reshape((1, source.shape[0]))\n",
        "        translation = predict_seq(model, tar_tokenizer, source)\n",
        "        raw_target, raw_src = raw_dataset[i]\n",
        "        print(f'{raw_src:30} {raw_target:25} {translation}')\n",
        "        if i >= limit: # Display some of the result\n",
        "            break\n",
        " \n",
        "# test on some training sequences\n",
        "# print('### Result on the Training Set ###')\n",
        "# compare_prediction(model, tar_tokenizer, trainX, train)\n",
        "\n",
        "# test on some test sequences\n",
        "print('\\n\\n### Result on the Test Set ###')\n",
        "compare_prediction(model, tar_tokenizer, testX, test[10000:20000,:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "### Result on the Test Set ###\n",
            "PSL (SOURCE)                   ENGLISH (TARGET)          AUTOMATIC TRANSLATION IN ENGLISH\n",
            "\n",
            "was salman quite frustrate     salman was quite frustrated salman was quite quite\n",
            "was nihal his new guitar show  nihal showed me his new guitar nihal showed his his his\n",
            "sajeel other week here come    sajeel comes here every other week sajeel comes here here week week\n",
            "was i direction change         i changed direction       i was the change\n",
            "i glad that was ranjhoo win    i am glad that ranjhoo won i am glad glad won won\n",
            "i do after whatever you want   i will do whatever you want i will do whatever whatever want\n",
            "i know when hassam lie now     i know when hassam is lying i know when when is lying\n",
            "he his own way live wish       he wishes to live his own way he lives to own his own\n",
            "manan his wife karachi live    manan and his wife live in karachi manan karachi karachi karachi karachi karachi\n",
            "was he home come evening yes no did he come home in the evening did he come home in the evening\n",
            "was i today able it do         i was able to do it today i did able it do it\n",
            "i it a lot appreciate          i appreciate it a lot     i appreciate appreciate a lot\n",
            "was you charge what            what did you charge       what did you charge\n",
            "you enchiladas eat yes no      do you eat enchiladas     can you eat\n",
            "was we our way lose            we lost our way           we lost our way way\n",
            "was arsh business control take arsh took control of the business najeeb took a control of\n",
            "noun naming word full after yes no will noun have been a naming word will noun have a a word word\n",
            "i faris arrest now not         i am not arresting faris  i am not taking faris\n",
            "sure make ranjhoo you see not  make sure ranjhoo does not see you do do not make make it\n",
            "was we in afternoon at two meet we met at two in the afternoon we met at at at at\n",
            "was i you bother want not      i did not want to bother you i did not want to bother you\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5cWGbrtSDVP"
      },
      "source": [
        "## Bleu Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQt6BGS5SDgv"
      },
      "source": [
        "def bleu_score(model, tokenizer, sources, raw_dataset):\n",
        "    # Get the bleu score of a model\n",
        "    actual, predicted = [], []\n",
        "    for i, source in enumerate(sources):\n",
        "        # translate encoded source text\n",
        "        source = source.reshape((1, source.shape[0]))\n",
        "        translation = predict_seq(model, tar_tokenizer, source)\n",
        "        raw_target, raw_src = raw_dataset[i]\n",
        "        actual.append([raw_target.split()])\n",
        "        predicted.append(translation.split())\n",
        "        \n",
        "    bleu_dic = {}\n",
        "    bleu_dic['1-grams'] = corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0))\n",
        "    bleu_dic['1-2-grams'] = corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0))\n",
        "    bleu_dic['1-3-grams'] = corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0))\n",
        "    bleu_dic['1-4-grams'] = corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25))\n",
        "    \n",
        "    return bleu_dic\n",
        "\n",
        "# Compute the BLEU Score\n",
        "# bleu_train = bleu_score(model, tar_tokenizer, trainX, train)\n",
        "bleu_test = bleu_score(model, tar_tokenizer, testX, test[10000:20000,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "s0my8ctPSDjX",
        "outputId": "9b25438d-c09f-427d-c8ba-5932ceae2596"
      },
      "source": [
        "plt.bar(x = bleu_test.keys(), height = bleu_test.values())\n",
        "plt.title(\"BLEU Score with 2nd 10000 test set\")\n",
        "plt.ylim((0,1))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WC4IFCJISDly",
        "outputId": "a27600f1-c60a-4b67-df10-d3b9ff1cb6ff"
      },
      "source": [
        "print(bleu_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'1-grams': 0.7206259512603983, '1-2-grams': 0.6112569202502609, '1-3-grams': 0.5575986997719323, '1-4-grams': 0.4486377701583157}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "764bwb57SDoW"
      },
      "source": [
        "## WER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmyVgJ3xSDrM",
        "outputId": "8435b5e8-8b21-417b-a8b9-803617d8a977"
      },
      "source": [
        "def word_for_id(integer, tokenizer):\n",
        "    # map an integer to a word\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == integer:\n",
        "            return word\n",
        "    return None\n",
        " \n",
        "def predict_seq(model, tokenizer, source):\n",
        "    # generate target from a source sequence\n",
        "    prediction = model.predict(source, verbose=0)[0]\n",
        "    integers = [np.argmax(vector) for vector in prediction]\n",
        "    target = list()\n",
        "    \n",
        "    for i in integers:\n",
        "        word = word_for_id(i, tokenizer)\n",
        "        if word is None:\n",
        "            break\n",
        "        target.append(word)\n",
        "    return ' '.join(target)\n",
        "\n",
        "def compare_prediction(model, tokenizer, sources, raw_dataset, limit=20):\n",
        "    # evaluate a model\n",
        "    actual, predicted = [], []\n",
        "    src = f'{source_str.upper()} (SOURCE)'\n",
        "    tgt = f'{target_str.upper()} (TARGET)'\n",
        "    pred = f'AUTOMATIC TRANSLATION IN {target_str.upper()}'\n",
        "    #print(f'{src:30} {tgt:25} {pred}\\n')\n",
        "    \n",
        "    for i, source in enumerate(sources): # translate encoded source text\n",
        "        source = source.reshape((1, source.shape[0]))\n",
        "        translation = predict_seq(model, tar_tokenizer, source)\n",
        "        raw_target, raw_src = raw_dataset[i]\n",
        "        #print(f'{raw_src:30} {raw_target:25} {translation}')\n",
        "        #print(translation)     #predicit\n",
        "        #print(raw_target)      #actual\n",
        "        actual.append(raw_target)\n",
        "        predicted.append(translation)\n",
        "        if i >= limit: # Display some of the result\n",
        "            return actual,predicted\n",
        "            break\n",
        " \n",
        "# # test on some training sequences!pip install jiwer\n",
        "# print('### Result on the Training Set ###')\n",
        "# compare_prediction(model, tar_tokenizer, trainX, train)\n",
        "\n",
        "# test on some test sequences\n",
        "print('\\n\\n### Result on the Test Set ###')\n",
        "Actual,Predicted=compare_prediction(model, tar_tokenizer, testX, test[10000:20000,:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "### Result on the Test Set ###\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CS3pF0c4SDuD",
        "outputId": "6c7f4cd2-49f7-45eb-9c36-799ffc84e099"
      },
      "source": [
        "!pip install jiwer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting jiwer\n",
            "  Downloading jiwer-2.2.0-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from jiwer) (1.19.5)\n",
            "Collecting python-Levenshtein\n",
            "  Downloading python-Levenshtein-0.12.2.tar.gz (50 kB)\n",
            "\u001b[?25l\r\u001b[K     |██████▌                         | 10 kB 19.6 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 20 kB 23.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 30 kB 25.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 40 kB 26.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 50 kB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from python-Levenshtein->jiwer) (57.4.0)\n",
            "Building wheels for collected packages: python-Levenshtein\n",
            "  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.2-cp37-cp37m-linux_x86_64.whl size=149866 sha256=15d8f0aab6f9267d1844ae8d52fdc7156f136c199299e4da4d5a6a390aad0a78\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/5f/ca/7c4367734892581bb5ff896f15027a932c551080b2abd3e00d\n",
            "Successfully built python-Levenshtein\n",
            "Installing collected packages: python-Levenshtein, jiwer\n",
            "Successfully installed jiwer-2.2.0 python-Levenshtein-0.12.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwb0RvmbSDwe",
        "outputId": "3cf940c5-3423-4aaf-9e89-1750e629325d"
      },
      "source": [
        "from jiwer import wer\n",
        "error=wer(Actual,Predicted)\n",
        "error"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.38016528925619836"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuNV8BzWSDzC"
      },
      "source": [
        "## TER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQ5yjpP1SUNL",
        "outputId": "bb0f2b4f-333a-4078-806c-1875512efec1"
      },
      "source": [
        "!pip install pyter3\n",
        "import pyter"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyter3\n",
            "  Downloading pyter3-0.3-py3-none-any.whl (4.1 kB)\n",
            "Installing collected packages: pyter3\n",
            "Successfully installed pyter3-0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHIi0wv9SUP1",
        "outputId": "a7621fe6-aca1-4197-cd78-13ece79be0ba"
      },
      "source": [
        "i=0\n",
        "sum=0\n",
        "while i<len(Actual):\n",
        "  #print(pyter.ter(Actual[i].split(),Predicted[i].split()))\n",
        "  sum+=pyter.ter(Actual[i].split(),Predicted[i].split())\n",
        "  i=i+1\n",
        "\n",
        "\n",
        "\n",
        "sum=sum/len(Actual)\n",
        "sum"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.40249433106575966"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTgANhgGSUSX"
      },
      "source": [
        "# For Last 5567 testing Instance.   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ev_VD5NBSUUx",
        "outputId": "71976e88-a940-40c9-bc22-24d6b4265c07"
      },
      "source": [
        "def word_for_id(integer, tokenizer):\n",
        "    # map an integer to a word\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == integer:\n",
        "            return word\n",
        "    return None\n",
        " \n",
        "def predict_seq(model, tokenizer, source):\n",
        "    # generate target from a source sequence\n",
        "    prediction = model.predict(source, verbose=0)[0]\n",
        "    integers = [np.argmax(vector) for vector in prediction]\n",
        "    target = list()\n",
        "    \n",
        "    for i in integers:\n",
        "        word = word_for_id(i, tokenizer)\n",
        "        if word is None:\n",
        "            break\n",
        "        target.append(word)\n",
        "    return ' '.join(target)\n",
        "\n",
        "def compare_prediction(model, tokenizer, sources, raw_dataset, limit=20):\n",
        "    # evaluate a model\n",
        "    actual, predicted = [], []\n",
        "    src = f'{source_str.upper()} (SOURCE)'\n",
        "    tgt = f'{target_str.upper()} (TARGET)'\n",
        "    pred = f'AUTOMATIC TRANSLATION IN {target_str.upper()}'\n",
        "    print(f'{src:30} {tgt:25} {pred}\\n')\n",
        "    \n",
        "    for i, source in enumerate(sources): # translate encoded source text\n",
        "        source = source.reshape((1, source.shape[0]))\n",
        "        translation = predict_seq(model, tar_tokenizer, source)\n",
        "        raw_target, raw_src = raw_dataset[i]\n",
        "        print(f'{raw_src:30} {raw_target:25} {translation}')\n",
        "        if i >= limit: # Display some of the result\n",
        "            break\n",
        " \n",
        "# test on some training sequences\n",
        "# print('### Result on the Training Set ###')\n",
        "# compare_prediction(model, tar_tokenizer, trainX, train)\n",
        "\n",
        "# test on some test sequences\n",
        "print('\\n\\n### Result on the Test Set ###')\n",
        "compare_prediction(model, tar_tokenizer, testX, test[20000:25567,:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "### Result on the Test Set ###\n",
            "PSL (SOURCE)                   ENGLISH (TARGET)          AUTOMATIC TRANSLATION IN ENGLISH\n",
            "\n",
            "they old woman help now not    they are not helping old woman they are not helping old woman\n",
            "was we chances had             we had the chances        we had a\n",
            "ashraf say i too nosey         ashraf says i am too nosey ashraf says i is too young\n",
            "i it much think full not       i haven t thought much about it i haven t thought it about it\n",
            "was i zabhi my room show       i showed my room to zabhi i showed her way way way\n",
            "was fight long last not        the fight did not last long nabi did not last the last\n",
            "i think was abbas my help want i think abbas wanted my help i think you want to help brother\n",
            "was it real scary              it was real scary         it was a red\n",
            "i small towns like             i like small towns        i like a reliable\n",
            "was i uniform wear now not     i was not wearing a uniform i was not wearing a\n",
            "mahi good captain              mahi is a good captain    mahi is a good speaker\n",
            "i rather busy be not           i would rather not be busy i would not want to busy\n",
            "was he so say not              he did not say so         he did not say so\n",
            "was he time arrive             he arrived in time        he arrived on time\n",
            "he death afraid                he is afraid of death     he is afraid afraid of guy\n",
            "was amjad say he you later call after amjad said he will call you later amjad said he will call call later\n",
            "i sure you many questions have i am sure you have many questions i am you you have questions\n",
            "was huzaifa look like was he happy huzaifa looked like he was happy zurgam looked like he was happy\n",
            "they tea drink now             they are drinking tea     they are drinking tea\n",
            "was omer daania beer buy offer omer offered to buy daania a beer omer offered to a a old\n",
            "was i monun me wait ask        i asked monun to wait for me i asked me to wait for\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzUYuW_ISdtp"
      },
      "source": [
        "## Bleu Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeNww1WbSdyN"
      },
      "source": [
        "def bleu_score(model, tokenizer, sources, raw_dataset):\n",
        "    # Get the bleu score of a model\n",
        "    actual, predicted = [], []\n",
        "    for i, source in enumerate(sources):\n",
        "        # translate encoded source text\n",
        "        source = source.reshape((1, source.shape[0]))\n",
        "        translation = predict_seq(model, tar_tokenizer, source)\n",
        "        raw_target, raw_src = raw_dataset[i]\n",
        "        actual.append([raw_target.split()])\n",
        "        predicted.append(translation.split())\n",
        "        \n",
        "    bleu_dic = {}\n",
        "    bleu_dic['1-grams'] = corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0))\n",
        "    bleu_dic['1-2-grams'] = corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0))\n",
        "    bleu_dic['1-3-grams'] = corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0))\n",
        "    bleu_dic['1-4-grams'] = corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25))\n",
        "    \n",
        "    return bleu_dic\n",
        "\n",
        "# Compute the BLEU Score\n",
        "# bleu_train = bleu_score(model, tar_tokenizer, trainX, train)\n",
        "bleu_test = bleu_score(model, tar_tokenizer, testX,test[20000:25567,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "eWpdAk0lSd0X",
        "outputId": "aa91cf27-22f4-4a16-e438-d89cd8d09b6d"
      },
      "source": [
        "plt.bar(x = bleu_test.keys(), height = bleu_test.values())\n",
        "plt.title(\"BLEU Score with last 5567 test set\")\n",
        "plt.ylim((0,1))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jy-ycO4nSd2H",
        "outputId": "851e5f99-3cff-413e-d696-3e002189f04d"
      },
      "source": [
        "print(bleu_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'1-grams': 0.7229104729701122, '1-2-grams': 0.6135062645591065, '1-3-grams': 0.559877004472567, '1-4-grams': 0.45247480876121837}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9783j7fSd4O"
      },
      "source": [
        "## WER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0HqrW84Sd8N",
        "outputId": "39f86dc5-69e2-4efe-ea2e-bbe4e11c6dca"
      },
      "source": [
        "def word_for_id(integer, tokenizer):\n",
        "    # map an integer to a word\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == integer:\n",
        "            return word\n",
        "    return None\n",
        " \n",
        "def predict_seq(model, tokenizer, source):\n",
        "    # generate target from a source sequence\n",
        "    prediction = model.predict(source, verbose=0)[0]\n",
        "    integers = [np.argmax(vector) for vector in prediction]\n",
        "    target = list()\n",
        "    \n",
        "    for i in integers:\n",
        "        word = word_for_id(i, tokenizer)\n",
        "        if word is None:\n",
        "            break\n",
        "        target.append(word)\n",
        "    return ' '.join(target)\n",
        "\n",
        "def compare_prediction(model, tokenizer, sources, raw_dataset, limit=20):\n",
        "    # evaluate a model\n",
        "    actual, predicted = [], []\n",
        "    src = f'{source_str.upper()} (SOURCE)'\n",
        "    tgt = f'{target_str.upper()} (TARGET)'\n",
        "    pred = f'AUTOMATIC TRANSLATION IN {target_str.upper()}'\n",
        "    #print(f'{src:30} {tgt:25} {pred}\\n')\n",
        "    \n",
        "    for i, source in enumerate(sources): # translate encoded source text\n",
        "        source = source.reshape((1, source.shape[0]))\n",
        "        translation = predict_seq(model, tar_tokenizer, source)\n",
        "        raw_target, raw_src = raw_dataset[i]\n",
        "        #print(f'{raw_src:30} {raw_target:25} {translation}')\n",
        "        #print(translation)     #predicit\n",
        "        #print(raw_target)      #actual\n",
        "        actual.append(raw_target)\n",
        "        predicted.append(translation)\n",
        "        if i >= limit: # Display some of the result\n",
        "            return actual,predicted\n",
        "            break\n",
        " \n",
        "# # test on some training sequences!pip install jiwer\n",
        "# print('### Result on the Training Set ###')\n",
        "# compare_prediction(model, tar_tokenizer, trainX, train)\n",
        "\n",
        "# test on some test sequences\n",
        "print('\\n\\n### Result on the Test Set ###')\n",
        "Actual,Predicted=compare_prediction(model, tar_tokenizer, testX, test[20000:25567,:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "### Result on the Test Set ###\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vvc0k21SUXS",
        "outputId": "c339cade-0223-4703-eee3-0064a3cfa768"
      },
      "source": [
        "!pip install jiwer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting jiwer\n",
            "  Downloading jiwer-2.2.0-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from jiwer) (1.19.5)\n",
            "Collecting python-Levenshtein\n",
            "  Downloading python-Levenshtein-0.12.2.tar.gz (50 kB)\n",
            "\u001b[?25l\r\u001b[K     |██████▌                         | 10 kB 23.8 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 20 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 30 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 40 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 50 kB 3.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from python-Levenshtein->jiwer) (57.4.0)\n",
            "Building wheels for collected packages: python-Levenshtein\n",
            "  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.2-cp37-cp37m-linux_x86_64.whl size=149874 sha256=e8117225075cad45bdb383e15cc243af586fadf82f304ab0604324617eca6294\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/5f/ca/7c4367734892581bb5ff896f15027a932c551080b2abd3e00d\n",
            "Successfully built python-Levenshtein\n",
            "Installing collected packages: python-Levenshtein, jiwer\n",
            "Successfully installed jiwer-2.2.0 python-Levenshtein-0.12.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfvY51rhSUZ4",
        "outputId": "18764876-deae-40a5-f3ec-43ad9b476a2b"
      },
      "source": [
        "from jiwer import wer\n",
        "error=wer(Actual,Predicted)\n",
        "error"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3220338983050847"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FDPWLqXSUdO"
      },
      "source": [
        "## TER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T390TAXCSD3S",
        "outputId": "305b8376-0b0e-424f-8c9f-7d0fca3303d1"
      },
      "source": [
        "!pip install pyter3\n",
        "import pyter"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyter3\n",
            "  Downloading pyter3-0.3-py3-none-any.whl (4.1 kB)\n",
            "Installing collected packages: pyter3\n",
            "Successfully installed pyter3-0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRx3KhtZS9ra",
        "outputId": "1df38973-a812-43aa-c6bc-d67ad3d587c1"
      },
      "source": [
        "i=0\n",
        "sum=0\n",
        "while i<len(Actual):\n",
        "  #print(pyter.ter(Actual[i].split(),Predicted[i].split()))\n",
        "  sum+=pyter.ter(Actual[i].split(),Predicted[i].split())\n",
        "  i=i+1\n",
        "\n",
        "\n",
        "\n",
        "sum=sum/len(Actual)\n",
        "sum"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.32573696145124714"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8UIlyGIS_wA"
      },
      "source": [
        "# Average WER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwWRRLE1S_yr",
        "outputId": "412ddcfa-3d89-45d7-d47a-50ee86d1ee5e"
      },
      "source": [
        "(0.154+0.380+0.322)/3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2853333333333334"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7ZxmY2XS_1Z"
      },
      "source": [
        "# Average TER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSyWgaLyS_4g",
        "outputId": "669421f5-a391-48d2-c642-8719ae555ecf"
      },
      "source": [
        "(0.161+0.402+0.325)/3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.29600000000000004"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srEEejWtS__N"
      },
      "source": [
        "gram1=(0.723+0.720+0.722)/3\n",
        "gram2=(0.615+0.611+0.613)/3\n",
        "gram3=(0.561+0.557+0.559)/3\n",
        "gram4=(0.453+0.448+0.452)/3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GibnF1pLTACz"
      },
      "source": [
        "bleu_dic = {}\n",
        "bleu_dic['1-grams']=gram1\n",
        "bleu_dic['1-2-grams']= gram2\n",
        "bleu_dic['1-3-grams']=gram3\n",
        "bleu_dic['1-4-grams']=gram4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8n2U8dKrxer",
        "outputId": "fbf2c1ef-9b2c-4978-af0d-04383d4fb918"
      },
      "source": [
        "print(bleu_dic)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'1-grams': 0.7216666666666667, '1-2-grams': 0.613, '1-3-grams': 0.559, '1-4-grams': 0.451}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "s5JVVEyCrxnU",
        "outputId": "92f976ff-a6a0-4bc4-ef06-6aba3acd15ed"
      },
      "source": [
        "plt.bar(x = bleu_dic.keys(), height = bleu_dic.values())\n",
        "plt.title(\"Average BLEU Score\")\n",
        "plt.ylim((0,1))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHSOCJOGrxpy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRcvoduArxtL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}